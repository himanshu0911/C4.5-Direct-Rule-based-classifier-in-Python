{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blocked-concert",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "# test comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-wealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetEntropy = 0"
   ]
  },
  {
   "cell_type": "raw",
   "id": "desperate-circus",
   "metadata": {},
   "source": [
    "C4.5 Algorithm (direct rule based classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-smoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "class treeNode():\n",
    "    def __init__(self, col=-1, colName='', value=None, results=None, rb=None, lb=None):\n",
    "        self.col = col \n",
    "        self.colName = colName; #name of the column the node represents\n",
    "        self.value = value #value of the node\n",
    "        self.results = results #results that are stored in the node\n",
    "        self.rb = rb #the right children of the node\n",
    "        self.lb= lb #the left children of the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-unknown",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partitionData(dataFrame, test_percentage):\n",
    "    tot_index = range(len(dataFrame)) \n",
    "    test_indexes = rnd.sample(tot_index, int(test_percentage * len(dataFrame))) \n",
    "    train_indexes = list(set(tot_index) ^ set(test_indexes)) \n",
    "\n",
    "    # use the indexes generated to build up dataframes\n",
    "    test_df = dataFrame.loc[test_indexes]\n",
    "    train_df = dataFrame.loc[train_indexes]\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-relaxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUniqueClasses(dataFrameColumn):\n",
    "    results = {}\n",
    "    for row in dataFrameColumn:\n",
    "        if row not in results: results[row] = 0 # initialise element in dictionary if not already there\n",
    "        results[row] += 1 # increment value\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-prairie",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEntropy(data, column):\n",
    "    entropy = 0.0\n",
    "    results = getUniqueClasses(data[column]) # get # of classes in data\n",
    "\n",
    "    for row in results.values():\n",
    "        p = float(row) / len(data[column]) # calculate probability value for each element in results\n",
    "        entropy -= p * np.log2(p) # calculate entropy\n",
    "\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-introduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findSplitPoints(data, column):\n",
    "    sorted = data.sort_values([column], ascending=True)\n",
    "    sorted_matrix = sorted[[column, 'Category']].to_numpy()\n",
    "    splitPoints = []\n",
    "    previous = sorted_matrix[0][1] # get target of the first element in sorted matrix\n",
    "    index = sorted.index.values; # get the indexes of each  element in the sorted matrix\n",
    "    counter = 0\n",
    "    for row in sorted_matrix:\n",
    "        if row[1] != previous: \n",
    "            splitPoints.append([index[counter - 1], sorted_matrix[counter - 1][0]])\n",
    "        counter += 1\n",
    "        previous = row[1]\n",
    "\n",
    "    return splitPoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-regular",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitSets(data, column, splitPoints):\n",
    "    sets_below = []\n",
    "    sets_above = []\n",
    "    # split the dataframe into 2 for each splitpoint\n",
    "    for i in range(len(splitPoints)):\n",
    "        df1 = data[data[column] <= data[column][splitPoints[i][0]]]  # everything below the splitpoint\n",
    "        df2 = data[data[column] > data[column][splitPoints[i][0]]]  # everything above it\n",
    "        # add to the lists\n",
    "        sets_below.append(df1)\n",
    "        sets_above.append(df2)\n",
    "\n",
    "    return sets_below, sets_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-gentleman",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInformationGain(data, column):\n",
    "    splitpoints = findSplitPoints(data, column)  # get splitpoints for this column\n",
    "    sets_below, sets_above = splitSets(data, column, splitpoints)  # split the data into sets based on these splitpoints\n",
    "    # lists to store the # of instances in each subset that are above and below each given threshold and their entropies\n",
    "    instances_above = []\n",
    "    instances_below = []\n",
    "    entropy_above = []\n",
    "    entropy_below = []\n",
    "    target_entropy = getEntropy(data, 'Category')  # get target entropy for the dataset\n",
    "    # get entropy for sets above and below each of the thresholds\n",
    "    for set in sets_below:\n",
    "        entropy_below.append(getEntropy(set, 'Category'))\n",
    "        instances_below.append(len(set))\n",
    "    for set in sets_above:\n",
    "        entropy_above.append(getEntropy(set, 'Category'))\n",
    "        instances_above.append(len(set))\n",
    "\n",
    "    totalInstances = []\n",
    "    infoGains = []\n",
    "    # work out the Information Gain for each threshold\n",
    "    for i in range(len(instances_below)):\n",
    "        totalInstances.append(instances_below[i] + instances_above[i])\n",
    "        probA = (instances_above[i] / float(totalInstances[i]))\n",
    "        probB = (instances_below[i] / float(totalInstances[i]))\n",
    "        infoGains.append(target_entropy - ((entropy_below[i] * probB) + (entropy_above[i] * probA)))\n",
    "\n",
    "    # work out the highest information gain for this column of the dataset\n",
    "    best_gain = i = counter = 0\n",
    "    for gain in infoGains:\n",
    "        if best_gain < gain:\n",
    "            best_gain = gain\n",
    "            counter = i # variable to hold the index in the list where the best gain occurs\n",
    "        i += 1\n",
    "\n",
    "    return best_gain, sets_below[counter], sets_above[counter], splitpoints[counter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-acceptance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data):\n",
    "    optimal_gain = -1\n",
    "    best = {}\n",
    "    columns = []\n",
    "    i = 0\n",
    "\n",
    "    for column in data:  # loop over each attribute\n",
    "        if column != 'Category':\n",
    "            try:\n",
    "                ig, set1, set2, split = getInformationGain(data, column)  # get information gain for each column\n",
    "                # column holds information that is used when creating a tree node.\n",
    "                # the values in each of the columns will be used below when creating nodes for the tree\n",
    "                columns.append({\"ig\": ig, \"left\": set1, \"right\": set2, 'col': i, 'split': split,'colName': column}) \n",
    "\n",
    "            # above code will work until the set1 and set2 values that would be returned bu the information Gain function will be 0\n",
    "            # in that case, an indexError will be thrown as we cannot access element 0 of the sets lists\n",
    "            # so if we catch that exception we know this data should be used as a leaf node and can format the tree information accordingly\n",
    "            except IndexError:\n",
    "                columns.append({\"ig\": 0, \"left\": [], \"right\": [], 'col': column, })\n",
    "        i += 1  # counter to get int value for row(used for tree node)\n",
    "\n",
    "    # loops through each column and pulls out the one with the best information gain for the given data\n",
    "    for val in range(len(columns)):\n",
    "\n",
    "        if columns[val]['ig'] > optimal_gain:\n",
    "            best = columns[val]\n",
    "            optimal_gain = columns[val]['ig']\n",
    "\n",
    "    # get data for left branch and data for right branch\n",
    "    left = best['left']\n",
    "    right = best['right']\n",
    "    # check if we have data for the left and right branches of the tree\n",
    "    # if they are = 0 it is the stop condition for recursion, and the else block will generate a leaf node for the tree\n",
    "    if len(best['left']) != 0 and len(best['right']) != 0:\n",
    "        return (treeNode(col=best['col'], colName=best['colName'], value=best['split'][1], results=None,\n",
    "                              rb=train(right), lb=train(left)))\n",
    "\n",
    "    else:\n",
    "        label = list(getUniqueClasses(data['Category']).keys()); #get label for the leaf node\n",
    "        return (treeNode(results=label[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-convenience",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(target_row, tree):\n",
    "    # base case to stop recursion -> we are at a leaf node\n",
    "    if tree.results != None:\n",
    "        return tree.results\n",
    "\n",
    "    else:\n",
    "        # gets the attribute from the target row that we are looking at\n",
    "        val = target_row[tree.col]\n",
    "        branch = None\n",
    "        if isinstance(val, int) or isinstance(val, float):\n",
    "            # checks the value of the tree against the value of the attribute from the target row\n",
    "            # go down right side\n",
    "            if val >= tree.value:\n",
    "                branch = tree.rb\n",
    "            # go down left side\n",
    "            else:\n",
    "                branch = tree.lb\n",
    "        # recur over the tree again, using either the left or right branch to determine where to go next\n",
    "        return classify(target_row, branch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-prospect",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTree(tree, space=''):\n",
    "    # Leaf node\n",
    "    if tree.results != None:\n",
    "        print(str(tree.results))\n",
    "\n",
    "    else:\n",
    "        print(str(tree.colName) + ' : ' + str(tree.value)) #name and splitpoint of current node\n",
    "        print(space + 'L ', end=\"\") #Print 'L' for left child\n",
    "        printTree(tree.lb, space + ' ') #Print left child\n",
    "        print(space + 'R ', end=\"\") #Print 'R' for right child\n",
    "        printTree(tree.rb, space + ' ') #Print right child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-token",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "def test_tree(data, labels, tree):\n",
    "   \n",
    "    # Loop over each row in test data frame and get the classification result for each index\n",
    "    for index, row in data.iterrows():\n",
    "        values.append([index, classify(row, tree)])\n",
    "\n",
    "    # Get the indexes from the test dataframe where each type occurs\n",
    "    indexes = labels.index.values\n",
    "    correct = incorrect = 0\n",
    "    # Loop over values list and compare the class that was classified by the tree\n",
    "    # and the class that was originally in the dataframe\n",
    "    for l in range(len(values)):\n",
    "        if values[l][0] == indexes[l] and values[l][1] == labels[indexes[l]]:\n",
    "            correct += 1 #increment the correctly classified #\n",
    "        else:\n",
    "            incorrect += 1 #increment the incorrectly classified #\n",
    "\n",
    "    return incorrect, correct, np.round(100 - (incorrect / (incorrect + correct)) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-arizona",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet = pd.read_csv('dmml dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-opposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet.drop('Unnamed: 0',axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-scene",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-johnston",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-magnet",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=dataSet.Sex.map({'m':0,'f':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-civilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-retreat",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-orientation",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-perth",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet.Category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-friendship",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=dataSet.Category.map({'0=Blood Donor':1,'0s=suspect Blood Donor':2,'1=Hepatitis':3,'2=Fibrosis':4,'3=Cirrhosis':5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-guarantee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-brass",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet.drop('Sex',axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-planning",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet.drop('Category',axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-induction",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet=pd.concat([df,dataSet,df1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-gilbert",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-catering",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [];\n",
    "tests = 1 \n",
    "train_data, test_data = train_test_split(dataSet, test_size=0.3)\n",
    "tree = train(train_data) # make tree\n",
    "types = test_data['Category'] # get types column from test_data\n",
    "        \n",
    "\n",
    "incorrect, correct, accuracy = test_tree(test_data, types, tree) # test the tree\n",
    "results.append(accuracy)\n",
    "\n",
    "        # print information to console\n",
    "\n",
    "print(\"Tree Generated:\" + \"\\n\")\n",
    "printTree(tree)\n",
    "print()\n",
    "print(\"Correctly Classified: \" + str(correct) + \" / \" + str(correct+incorrect))\n",
    "print(\"Accuracy: \" + str(accuracy))\n",
    "print()\n",
    "\n",
    "sum = 0\n",
    "for r in range(len(results)):\n",
    "    sum += results[r]\n",
    "average = sum/tests\n",
    "\n",
    "print(\"Average Accuracy after \" + str(tests) + \" runs\")\n",
    "print(average)\n",
    "    #test_start\n",
    "    \n",
    "y_test=types\n",
    "print(y_test)\n",
    "    \n",
    "vp=values\n",
    "from pandas import DataFrame\n",
    "df = DataFrame(values,columns=['index','pred_Target'])\n",
    "app=df['pred_Target']\n",
    "y_pred = app\n",
    "print(y_pred)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy:\",accuracy_score(y_test,y_pred)*100)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-webcam",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
